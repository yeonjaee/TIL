{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP 토큰화"
      ],
      "metadata": {
        "id": "FFBvcg9QQ9-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 전처리 함수 호출\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "tuv5s8skLCza"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '해보지 않으면 해낼 수 없다' # 전처리할 텍스트"
      ],
      "metadata": {
        "id": "y4DjqBuiLHXE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 텍스트 토큰화\n",
        "result = text_to_word_sequence(text)\n",
        "print('\\n원문:\\n', text)\n",
        "print('\\n토큰화:\\n', result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu4ZWRs1LMCL",
        "outputId": "37c56645-8d8a-4874-8b04-caeee744c8c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "원문:\n",
            " 해보지 않으면 해낼 수 없다\n",
            "\n",
            "토큰화:\n",
            " ['해보지', '않으면', '해낼', '수', '없다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "6qkvCcdhLV3b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리하려는 문장 3개.\n",
        "\n",
        "docs = ['얻은 것은 이미 끝난 것이다. 기쁨의 본질은 그 과정에 있으므로.',\n",
        "        '거짓말로 인한 분노는 평생 간다. 진실로 인한 분노는 오래갈 수 없다.',\n",
        "        '목적없는 공부는 기억에 해가 될 뿐이며, 머리속에 들어온 어떤 것도 간직하지 못한다.',\n",
        "        ]"
      ],
      "metadata": {
        "id": "5s2bh2bELbGi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "bkH7o9dOLqS6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n단어 카운트:\\n', token.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8_FsUEqLtg7",
        "outputId": "96943646-43f3-4e72-9778-fe4fea3220e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "단어 카운트:\n",
            " OrderedDict([('얻은', 1), ('것은', 1), ('이미', 1), ('끝난', 1), ('것이다', 1), ('기쁨의', 1), ('본질은', 1), ('그', 1), ('과정에', 1), ('있으므로', 1), ('거짓말로', 1), ('인한', 2), ('분노는', 2), ('평생', 1), ('간다', 1), ('진실로', 1), ('오래갈', 1), ('수', 1), ('없다', 1), ('목적없는', 1), ('공부는', 1), ('기억에', 1), ('해가', 1), ('될', 1), ('뿐이며', 1), ('머리속에', 1), ('들어온', 1), ('어떤', 1), ('것도', 1), ('간직하지', 1), ('못한다', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n문장 카운트:\\n', token.document_count)\n",
        "print('\\n각 단어가 몇 개의 문장에 포함되어 있는가:\\n', token.word_docs)\n",
        "print('\\n각 단어에 매겨진 인덱스 값:\\n', token.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPTpsAU6LydD",
        "outputId": "6727ab14-a473-4a4d-c3a7-15076fc07c95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "문장 카운트:\n",
            " 3\n",
            "\n",
            "각 단어가 몇 개의 문장에 포함되어 있는가:\n",
            " defaultdict(<class 'int'>, {'기쁨의': 1, '얻은': 1, '것은': 1, '본질은': 1, '끝난': 1, '있으므로': 1, '과정에': 1, '이미': 1, '것이다': 1, '그': 1, '없다': 1, '평생': 1, '인한': 1, '수': 1, '분노는': 1, '오래갈': 1, '진실로': 1, '거짓말로': 1, '간다': 1, '간직하지': 1, '것도': 1, '못한다': 1, '목적없는': 1, '기억에': 1, '어떤': 1, '해가': 1, '뿐이며': 1, '머리속에': 1, '공부는': 1, '들어온': 1, '될': 1})\n",
            "\n",
            "각 단어에 매겨진 인덱스 값:\n",
            " {'인한': 1, '분노는': 2, '얻은': 3, '것은': 4, '이미': 5, '끝난': 6, '것이다': 7, '기쁨의': 8, '본질은': 9, '그': 10, '과정에': 11, '있으므로': 12, '거짓말로': 13, '평생': 14, '간다': 15, '진실로': 16, '오래갈': 17, '수': 18, '없다': 19, '목적없는': 20, '공부는': 21, '기억에': 22, '해가': 23, '될': 24, '뿐이며': 25, '머리속에': 26, '들어온': 27, '어떤': 28, '것도': 29, '간직하지': 30, '못한다': 31}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 원핫 인코딩"
      ],
      "metadata": {
        "id": "5ln8J5abRFqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zQtBZwuvMUv8",
        "outputId": "e7a6feb3-0d98-4be1-ba29-55e2105b4418"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'해보지 않으면 해낼 수 없다'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts([text])\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFeLnKqTMHIq",
        "outputId": "7bb546e2-0c55-4528-d5ca-d2f6687a96eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'해보지': 1, '않으면': 2, '해낼': 3, '수': 4, '없다': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences([text])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wu9fBW8MNCC",
        "outputId": "1de2edb4-71fb-4f35-be79-698502dbccd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 인덱스 수에 하나를 추가해서 원-핫 인코딩 배열 만들기\n",
        "word_size = len(token.word_index) + 1\n",
        "x = to_categorical(x, num_classes = word_size)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4qhAP8WMcyS",
        "outputId": "1b13101e-e4f3-4e07-e4f3-18081a7205d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 임베딩"
      ],
      "metadata": {
        "id": "lIjG05GmRJ7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import tensorflow as tf\n",
        "from numpy import array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(16,4))"
      ],
      "metadata": {
        "id": "HpmpokdgNR5p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['존잼','최고','명작이네요','추천','2회차','별로','노잼','비추','지루','돈아깝다']"
      ],
      "metadata": {
        "id": "-rKCkK3WM749"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 긍정 리뷰는 1, 부정 리뷰는 0으로 클래스 지정\n",
        "classes = array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "metadata": {
        "id": "l6HC2tOQNAB2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer() \n",
        "token.fit_on_texts(docs)    # 토큰화\n",
        "print(token.word_index) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXRNReQcNQIK",
        "outputId": "f38a96ec-3e20-4c15-e3c3-66296a148de5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'존잼': 1, '최고': 2, '명작이네요': 3, '추천': 4, '2회차': 5, '별로': 6, '노잼': 7, '비추': 8, '지루': 9, '돈아깝다': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰에 지정된 인덱스로 새로운 배열을 생성\n",
        "x = token.texts_to_sequences(docs)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXZDhThnQS_6",
        "outputId": "dd447404-6198-43cf-8b1d-8c239c0b722b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩, 각각의 데이터의 길이를 4로 맞춤\n",
        "padded_x = pad_sequences(x, 4)  \n",
        "\"\\n패딩 결과\\n\", print(padded_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64MUiA3NOetW",
        "outputId": "bd263990-032e-4310-a0a4-a8531c9784c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  1]\n",
            " [ 0  0  0  2]\n",
            " [ 0  0  0  3]\n",
            " [ 0  0  0  4]\n",
            " [ 0  0  0  5]\n",
            " [ 0  0  0  6]\n",
            " [ 0  0  0  7]\n",
            " [ 0  0  0  8]\n",
            " [ 0  0  0  9]\n",
            " [ 0  0  0 10]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\\n패딩 결과\\n', None)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_size = len(token.word_index)+1 # 임베딩에 입력될 단어 수 지정"
      ],
      "metadata": {
        "id": "Kevn3guDOgq5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 8, input_length=4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded_x, classes, epochs=20)\n",
        " \n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(padded_x, classes)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRKL0XmZOijI",
        "outputId": "03977a50-ba90-4e14-eb5c-daa3948cb312"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6891 - accuracy: 0.6000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6883 - accuracy: 0.7000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6876 - accuracy: 0.7000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6868 - accuracy: 0.7000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6860 - accuracy: 0.7000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6853 - accuracy: 0.7000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6845 - accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6837 - accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.8000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6822 - accuracy: 0.8000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.8000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6806 - accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.8000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6782 - accuracy: 0.8000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6774 - accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.6748 - accuracy: 1.0000\n",
            "\n",
            " Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 최적화 함수 adam()을 사용\n",
        "- 30번 반복하고나서 정확도를 계산하여 출력하게 했다.\n",
        "\n",
        "- 학습 결과가 10개의 리뷰 샘플 중 몇 개를 맞추었는지 보여준다."
      ],
      "metadata": {
        "id": "30nVHszCQwE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pzo496uMOkhC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}